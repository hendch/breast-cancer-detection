project:
  random_state: 42
  test_size: 0.2

mlp:
  hidden_layers: [256, 256, 256]
  dropout: 0.3
  learning_rate: 0.0001
  batch_size: 16
  epochs: 300

  early_stopping:
    enabled: true
    monitor: val_loss
    patience: 30
    restore_best_weights: true

  validation_split: 0.1

svm:
  C: 10
  gamma: "scale"
  kernel: "rbf"
  probability: false

linear_regression:
  best_params:
    degree: 1
    alpha: 0.01

softmax_regression:
  best_params:
    C: 1.0
    solver: "liblinear"

gru_svm:
  best_params:
    units: 32
    layers: 1
    dropout: 0.3
    learning_rate: 0.001
    batch_size: 16
    epochs: 200

